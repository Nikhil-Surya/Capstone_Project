{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set API key\n",
    "api_key = 'API KEY'\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "# Templates\n",
    "template = \"\"\"You are an expert assistant providing accurate, honest, and detailed information.\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# Combine both into a chat prompt\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Initialize chain\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(openai_api_key=api_key, model_name='gpt-4' ),\n",
    "    prompt=chat_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ad467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read prompts from a text file \n",
    "def read_prompts_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip() for line in file if line.strip()]\n",
    "\n",
    "# Dataset\n",
    "prompt_file = 'input.txt'\n",
    "prompts_list = read_prompts_from_file(prompt_file)\n",
    "\n",
    "\n",
    "output_data = []\n",
    "\n",
    "# Running the chain\n",
    "for prompt in prompts_list:\n",
    "    # Generate prediction\n",
    "    prediction = chain.run(prompt)\n",
    "    \n",
    "    # Store the prompt and prediction in the output_data list\n",
    "    output_data.append({\n",
    "        'Prompt': prompt,\n",
    "        'Response': prediction.strip()\n",
    "    })\n",
    "    print(f'\\nPROMPT: {prompt}')\n",
    "    print(f'RESPONSE: {prediction.strip()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Save the output to a CSV file\n",
    "csv_file = 'prompts_responses.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['Prompt', 'Response'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_data)\n",
    "\n",
    "# Save the output to an Excel file\n",
    "excel_file = 'prompts_responses.xlsx'\n",
    "df = pd.DataFrame(output_data)\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"\\nResults saved to {csv_file} and {excel_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
